# Endotheliosis Quantifier — Product Overview

## Vision
- Computer vision pipeline for researchers to automatically segment glomeruli and quantify glomerular endotheliosis on H&E slides.
- Initial approach: transfer learning from a mitochondria EM model, fine-tuning a U-Net to detect glomerular "line" structures in standard H&E.

## Target Users
- Kidney pathology and biomedical imaging researchers who need reproducible, automated quantification of endotheliosis from digital slides or derived image patches.

## Current State (from codebase)
- 4-step pipeline in `scripts/main/`:
  - Data prep and cache generation (`1_load_data_for_segmentation_analysis.py`).
  - Segmentation model training (U-Net fine-tuning; `2_train_glomeruli_segmenter.py`).
  - ROI extraction and CNN feature extraction (`3_run_feature_extractor_model.py`).
  - Quantification via regression (currently Random Forest on features; `4_quantify_endotheliosis.py`).
- Utilities for preprocessing, patch generation/validation, and environment/runtime checks.
- Apple Silicon environment present with TensorFlow-Metal acceleration.

## Roadmap
### Phase 0: Already Completed
- [x] End-to-end scripts for data prep → segmentation → feature extraction → quantification
- [x] Caching of datasets and features for faster iteration
- [x] Basic regression-based quantification with validation reporting

### Phase 1: Current Development
- [ ] Rename repository to `endotheliosis_quantifier` (current: `endotheliosisQuantifier_LEARN`)
- [ ] Adopt `src/eq` package layout and expose CLI entrypoints (e.g., `eq-segment`, `eq-extract`, `eq-quantify`)
- [ ] Consolidate duplicate/legacy scripts (keep a single ROI extractor, a single feature extractor, a single quantifier)
- [ ] Centralize configuration (data paths, cache dirs, model paths) via a single config module
- [ ] Decide framework for training/inference (FastAI vs TensorFlow/Keras) with cross-platform constraints
- [ ] Add small sample dataset + smoke tests for each step

### Phase 2: Near-term Enhancements
- [ ] Improve segmentation training pipeline (reproducible configs, metrics, checkpoints)
- [ ] Package release preparation (documentation, README examples, versioning)
- [ ] Batch inference CLI to support researchers running their datasets

### Phase 3: Longer-term
- [ ] Optional GPU training path on Windows via WSL2 + CUDA (RTX 3080)
- [ ] Model zoo and versioned checkpoints for reproducible research
- [ ] Optional interactive notebooks with minimal setup for demos

## Decisions and Constraints
- Must run on macOS Apple Silicon (M1) for inference and light workflows.
- Heavy training may require a Windows PC with RTX 3080 (WSL2 + CUDA); keep training functionality intact, but prioritize easy "production" inference for general users.
- Aim for a scalable, well-documented package repository that others can clone and run on their data.

## Platforms and Tech Stack
- Current: Python 3.9, TensorFlow/Keras (with `tensorflow-macos` + `tensorflow-metal`), OpenCV, scikit-learn, NumPy, SciPy, Matplotlib.
- Alternative: Evaluate FastAI for training if it improves cross-platform developer experience while preserving M1 compatibility.

## Environment & Standards
- Conda environment name: `eq` (see `environment.yml`). Always install and run inside this environment.
- Follow the Python code style in `.agent-os/standards/code-style/python-style.md`.
- Prefer tidy, testable, and documented functions; separate test scripts for new logic to ensure reproducibility.
