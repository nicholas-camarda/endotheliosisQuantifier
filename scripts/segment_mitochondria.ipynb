{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run these in the command line before executing this notebook\n",
    "# ! pip install fastai; \n",
    "# ! pip install ipykernel torch torchaudio torchvision\n",
    "\n",
    "# NOTE: Start with this article to understand!!\n",
    "# https://walkwithfastai.com/Binary_Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision.all import *\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "DisplayHandle.update = update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory = Path.cwd().joinpath('../')\n",
    "train_path = project_directory.joinpath('data/mitochondria_data/training')\n",
    "# print(train_path)\n",
    "\n",
    "test_path = project_directory.joinpath('data/mitochondria_data/testing')\n",
    "# print(test_path)\n",
    "\n",
    "test_image_paths = test_path / \"images\"\n",
    "init_image_paths = train_path / \"images\"\n",
    "test_mask_paths = test_path / \"masks\"\n",
    "init_mask_paths = train_path / \"masks\"\n",
    "\n",
    "def get_union_of_directories(dir1, dir2):\n",
    "    # List of Path objects\n",
    "    directories = [dir1, dir2]\n",
    "\n",
    "    # List comprehension to get all .tif files from both directories\n",
    "    res = [file for directory in directories for file in directory.glob('*.tif')]\n",
    "    return res\n",
    "\n",
    "image_files = get_union_of_directories(test_image_paths, init_image_paths)\n",
    "mask_files = get_union_of_directories(test_mask_paths, init_mask_paths)\n",
    "\n",
    "print(len(image_files))\n",
    "print(len(mask_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_size = Image.open(image_files[0]).size\n",
    "print(f'Size of an image: {input_image_size}')\n",
    "square_size = input_image_size[0]\n",
    "\n",
    "\n",
    "print(np.unique(Image.open(image_files[1])))\n",
    "print(np.unique(Image.open(mask_files[1])))\n",
    "\n",
    "print(image_files[1])\n",
    "print(mask_files[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the mask file path from an image file path\n",
    "import matplotlib.pyplot as plt\n",
    "# Now, our mask isn't set up how fastai expects, in which the mask points are not all in a row. We need to change this:\n",
    "# # We'll do this through an n_codes function. What this will do is run through our masks and build a set based on the unique values \n",
    "# present in our masks. \n",
    "# From there we will build a dictionary that will replace our points once we load in the image\n",
    "def n_codes(fnames, is_partial=True):\n",
    "  \"Gather the codes from a list of `fnames`, full file paths\"\n",
    "  vals = set()\n",
    "  if is_partial:\n",
    "    random.shuffle(fnames)\n",
    "    fnames = fnames[:10]\n",
    "  for fname in fnames:\n",
    "    msk = np.array(PILMask.create(fname))\n",
    "    for val in np.unique(msk):\n",
    "      if val not in vals:\n",
    "        vals.add(val)\n",
    "  vals = list(vals)\n",
    "  p2c = dict()\n",
    "  for i,val in enumerate(vals):\n",
    "    p2c[i] = vals[i]\n",
    "  return p2c\n",
    "\n",
    "p2c = n_codes(mask_files)\n",
    "\n",
    "print(p2c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = image_files[0]\n",
    "image_file.parent.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_file(image_file, p2c):\n",
    "    # this is the base path\n",
    "    base_path = image_file.parent.parent.parent\n",
    "    # get training or testing from here\n",
    "    first_name = re.findall(string=image_file.name, pattern=r\"^[training|testing|]*\")[0]\n",
    "    # get the sample number\n",
    "    nums = re.findall(string=image_file.name, pattern=r\"\\d+_\\d+_\\d+\")[0]  # remove from list\n",
    "    # put the whole thing together\n",
    "    str_name = f'{first_name}_groundtruth_' + nums + image_file.suffix\n",
    "    # attach it to the correct path\n",
    "    mask_path = (base_path / first_name / 'masks' / str_name)\n",
    "    # convert to an array (mask)\n",
    "    msk = np.array(PILMask.create(mask_path))\n",
    "    mx = np.max(msk)\n",
    "    # find all the possible values in the mask (0,255)\n",
    "    for i, val in enumerate(p2c):\n",
    "        msk[msk==p2c[i]] = val\n",
    "    return PILMask.create(msk)\n",
    "\n",
    "\n",
    "def get_y(o): \n",
    "    return get_mask_file(o, p2c)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(5, 5))\n",
    "im = PILImage.create(image_files[0])\n",
    "im.show(ax[0])\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "msk = get_y(image_files[0])\n",
    "msk.show(ax[1])\n",
    "ax[1].set_title(\"Mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(img_fn):\n",
    "    img = PILImage.create(img_fn)\n",
    "    msk = PILMask.create(get_mask_file(img_fn, p2c))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(5, 5))\n",
    "\n",
    "    # Show image on left axis\n",
    "    img.show(ax=ax[0])\n",
    "\n",
    "    # Show mask on right axis\n",
    "    msk.show(ax=ax[1], alpha=1)\n",
    "\n",
    "    print(f\"Unique values in the mask: {np.unique(np.array(msk))}\")\n",
    "\n",
    "\n",
    "# Show a few masks and their unique values\n",
    "for image_path in image_files[:5]:\n",
    "    show_mask(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note: get_image_files takes a path object. If you already ahve a list of paths, then just pass that as a lambda function\n",
    "# set up the datablock \n",
    "mitos = DataBlock(blocks=(ImageBlock, MaskBlock(codes=np.array(['not_mito', 'mito']))),\n",
    "                  splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "                  get_items=lambda x: image_files,\n",
    "                  get_y=get_y, #get_mask_file,  # Use the custom getter function for masks\n",
    "                  item_tfms=[RandomResizedCrop(512, min_scale=0.3)],  # this is super important - upscale the crop at each batch randomly\n",
    "                  batch_tfms=[*aug_transforms(size=224,\n",
    "                                              flip_vert=True,\n",
    "                                              max_rotate=30,\n",
    "                                              min_zoom=0.8,\n",
    "                                              max_zoom=1.15,\n",
    "                                              max_warp=0.3)],\n",
    "                  n_inp=1,\n",
    "                  )\n",
    "\n",
    "batch_size = 16\n",
    "dls = mitos.dataloaders(image_files,  bs=batch_size)\n",
    "mitos.summary(image_files, bs=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=batch_size, vmin=0, vmax=1, figsize=(batch_size/2,batch_size/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dls.one_batch()\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Target shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=ranger\n",
    "learn = unet_learner(dls, resnet34, metrics=Dice, opt_func=opt)\n",
    "\n",
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a good learning rate \n",
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_min, lr_steep, lr_valley, lr_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short test to see if we're good\n",
    "\n",
    "# # Pretty much always gonna use the default, valley, but useful to see the other suggestions\n",
    "# learn.fit_one_cycle(3, lr_valley)\n",
    "# learn.show_results(max_n=3, figsize=(2,3))\n",
    "\n",
    "\n",
    "# pick from the graph above or use to make your own LR\n",
    "my_lr = 1e-3\n",
    "\n",
    "n_epochs = 50\n",
    "# optimizer \n",
    "opt = ranger\n",
    "# feed the model the dataloader and the backbone e.g. resnet, with its metrics and optimizer\n",
    "learn = unet_learner(dls, resnet34, metrics=Dice, opt_func=opt)\n",
    "# fine tune it\n",
    "\n",
    "print(f\"\"\"Learning rate = {my_lr}\n",
    "      Epochs = {n_epochs}\"\"\")\n",
    "print(f'Employing loss function: {learn.loss_func}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune the model\n",
    "learn.fine_tune(n_epochs, my_lr,\n",
    "                cbs=EarlyStoppingCallback(monitor='valid_loss', min_delta=0.001, patience=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 This is the training loss at the end of the last epoch. \n",
    "# The training loss measures the difference between the model's predictions \n",
    "# and the true target values. A lower value indicates that the model is\n",
    "# performing better on the training data.\n",
    "\n",
    "#2 This is the value of the Dice coefficient (or Sørensen–Dice coefficient) metric \n",
    "# at the end of the last epoch. The Dice coefficient is a performance metric \n",
    "# commonly used for image segmentation tasks, measuring the similarity between two sets. \n",
    "# In this case, it compares the predicted segmentation mask and the ground truth mask.\n",
    "# The Dice coefficient ranges from 0 to 1, where a higher value indicates better performance\n",
    "# (a value of 1 means the predicted mask and ground truth mask are identical).\n",
    "\n",
    "rec_vals = learn.recorder.values[-1]\n",
    "print(len(rec_vals))\n",
    "print(f'Training loss: {rec_vals[0]}')\n",
    "print(f'Validation loss: {rec_vals[1]}')\n",
    "print(f'Dice Coef: {rec_vals[2]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=6,figsize=(2,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "os.makedirs(\"../segmentation_model_dir\", exist_ok =True)\n",
    "fname = f\"dynamic_unet_seg_model-e{n_epochs}_b{batch_size}.pkl\"\n",
    "print(fname)\n",
    "\n",
    "output_file = project_directory.joinpath(Path(\"segmentation_model_dir\").joinpath(fname))\n",
    "\n",
    "# saves the whole model, not just the weights\n",
    "learn.export(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "import torch\n",
    "# # Delete the objects\n",
    "# del learn\n",
    "# del dls\n",
    "# del mitos\n",
    "\n",
    "\n",
    "# Call the garbage collector\n",
    "gc.collect()\n",
    "\n",
    "# clear the GPU cache\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
